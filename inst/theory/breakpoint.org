#+TITLE: Breakpoint model
#+Author: 

* Single breakpoint, single slope

** Theory

Consider a response variable \(Y\) and an explanatory variable \(X\)
related by:
#+BEGIN_EXPORT latex
\begin{align*}
Y = \beta X - \beta (X - \psi)_+ + \varepsilon
\end{align*}
#+END_EXPORT

\noindent where \((\beta,\psi) \in \Real^2\), \(\varepsilon
\sim \Gaus[0,\sigma^2]\), and \((x)_+=x\) if \(x>0\) and 0
otherwise. Introduce \(\Theta = (\beta,\psi,\sigma^2)\), we can
express the likelihood relative to \(n\) iid observations as:
#+BEGIN_EXPORT latex
\begin{align*}
\Likelihood(\Theta) = \prod_{i=1}^n \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{(Y_i - \beta X_i + \beta (X_i - \psi)_+)^2}{2\sigma^2}\right)
\end{align*}
#+END_EXPORT
and the log-likelihood as:
#+BEGIN_EXPORT latex
\begin{align*}
\likelihood(\Theta) = - \frac{n}{2} \log(2\pi) - \frac{n}{2} \log(\sigma^2) - \sum_{i=1}^n \frac{\left(Y_i - \beta X_i + \beta (X_i - \psi)_+\right)^2}{2\sigma^2}
\end{align*}
#+END_EXPORT

\noindent Maximizing the likelihood with respect to \(\Theta_\mu =
(\beta,\psi)\) is equivalent to minimizing the mean squared
error:
#+BEGIN_EXPORT latex
\begin{align*}
\likelihood(\Theta_\mu) = \sum_{i=1}^n (Y_i - \beta X_i + \beta (X_i - \psi)_+)^2
\end{align*}
#+END_EXPORT

\noindent which is equivalent to first minimizing
w.r.t. \(beta\), i.e. plug-in the OLS estimator:
#+BEGIN_EXPORT latex
\begin{align*}
\tilde{\beta}(\psi) &= \frac{\sum_{i=1}^n X_i Y_i - (X_i - \psi)_+ Y_i}{\sum_{i=1}^n (X_i + (X_i - \psi)_+)^2} = \frac{\sum_{i=1}^n \Ind[X_i \leq \psi] X_i Y_i}{\sum_{i=1}^n \Ind[X_i \leq \psi] X^2_i} \\
\end{align*}
#+END_EXPORT

and then minimize w.r.t. \(\psi\):
#+BEGIN_EXPORT latex
\begin{align*}
\likelihood(\psi) &= \sum_{i=1}^n (Y_i - \tilde{\beta}(\psi) X_i + \tilde{\beta}(\psi) (X_i - \psi)_+)^2
\end{align*}
#+END_EXPORT

So the first 'derivative' should solve:
#+BEGIN_EXPORT latex
\begin{align*}
0 =& -2 \sum_{i=1}^n \left[
  \frac{\partial \tilde{\beta}(\psi)}{\partial \psi} (X_i - (X_i - \psi)_+)
- \tilde{\beta}(\psi)\frac{\partial (X_i - \psi)_+}{\partial \psi}\right]
(Y_i - \tilde{\beta}(\psi) X_i + \tilde{\beta}(\psi)(X_i - \psi)_+ ) \\
0 =& \frac{\partial \tilde{\beta}(\psi)}{\partial \psi} \sum_{i=1}^n (X_i - (X_i - \psi)_+)(Y_i - \tilde{\beta}(\psi) X_i + \tilde{\beta}(\psi)(X_i - \psi)_+ ) \\
& - \tilde{\beta}(\psi)\sum_{i=1}^n\frac{\partial (X_i - \psi)_+}{\partial \psi}(Y_i - \tilde{\beta}(\psi) X_i + \tilde{\beta}(\psi)(X_i - \psi)_+ ) 
\end{align*}
#+END_EXPORT

Assuming that the breakpoint does not coincide with any datapoint:
#+BEGIN_EXPORT latex
\begin{align*}
0 =& - \tilde{\beta}(\psi)\sum_{i=1}^n \Ind[X_i \geq \psi] (Y_i - \tilde{\beta}(\psi) \psi)  \\
\frac{1}{n}\sum_{i=1}^n \Ind[X_i \geq \psi] Y_i =& \tilde{\beta}(\psi) \psi
\end{align*}
#+END_EXPORT

So the breakpoint should be such that the average post-breakpoint value equal the fitted plateau.

\clearpage

** Example

#+BEGIN_SRC R :exports both :results output :session *R* :cache no
library(lmbreak)

set.seed(10)
df10 <- simBreak(c(1, 100), breakpoint = c(0,2,4),
                 slope = c(1,0), sigma = 0.05)
e.lmbreak10 <- lmbreak(Y ~ 0 + bp(X, pattern = "10", start = c(2)),
                       data = df11)
model.tables(e.lmbreak10)
#+END_SRC

#+RESULTS:
:            X duration intercept    slope
: 1 0.05773562 1.940351  0.000000 1.003169
: 2 1.99808692 1.847123  1.946501 0.000000
: 3 3.84520966       NA  1.946501       NA

OLS:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
XX <- df10$X - pmax(df10$X-coef(e.lmbreak10),0)
solve(t(XX) %*% XX) %*% t(XX) %*% df11$Y
#+END_SRC

#+RESULTS:
:          [,1]
: [1,] 1.003168

Explicit OLS:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
sum((df10$X < coef(e.lmbreak10))*df10$X*df10$Y)/sum((df10$X < coef(e.lmbreak10))*df10$X^2)
#+END_SRC

#+RESULTS:
: [1] 1.003169

Full likelihood:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
calcLogLik <- function(theta){
  beta <- theta["beta"]
  gamma <- theta["gamma"]
  psi <- theta["psi"]
  sigma <- theta["sigma"]
  as.double(-NROW(df11)/2 * log(2*pi) - NROW(df11)/2 * log(sigma) - sum((df11$Y - beta * df11$X - gamma * pmax(df11$X - psi,0))^2)/(2*sigma))
}
theta <- c(beta = unname(coef(e.lmbreak11$model)["Us0"]),
           gamma = unname(coef(e.lmbreak11$model)["Us1"]),
           psi = 1.98454227,
           sigma = sigma(e.lmbreak11$model)^2)
calcLogLik(theta = theta)
logLik(e.lmbreak11$model)
#+END_SRC

#+RESULTS:
: [1] 162.2538
: 'log Lik.' 162.2768 (df=4)

Profile likelihood:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
calcProfLik <- function(psi){ ## psi <- 1
  XX <- cbind(df11$X, pmax(df11$X-psi,0))
  OLS <- as.double(solve(t(XX) %*% XX) %*% t(XX) %*% df11$Y)
  sigma <- sum((df11$Y - XX %*% OLS)^2)/(NROW(df11)-3)
   - NROW(df11)/2 * log(2*pi) - NROW(df11)/2 * log(sigma) - (NROW(df11)-3)/2
}
calcProfLik(theta["psi"])

df.gridPsi <- data.frame(psi = seq(0.5,3.5,length.out=1000))
df.gridPsi$logLik <- sapply(df.gridPsi$psi,calcProfLik)
ggplot(df.gridPsi, aes(x=psi,y=logLik)) + geom_line()
#+END_SRC

#+RESULTS:
: [1] 162.2538


Score:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
library(numDeriv)
jacobian(calcLogLik, theta)
jacobian(calcProfLik, theta["psi"])
#+END_SRC
#+RESULTS:
:            [,1]        [,2]        [,3]      [,4]
: [1,] 0.02242403 0.006498193 0.007915766 -638.0514
:             [,1]
: [1,] 0.001578588

Hessian:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
Hall <- hessian(calcLogLik, theta)
Iall <- solve(-Hall)

Iall[3,3] - Iall[3,1:2] %*% solve(Iall[1:2,1:2]) %*% Iall[1:2,3]

Hpsi <- hessian(calcProfLik, theta["psi"])
Ipsi <- solve(-Hpsi)

Ipsi/(Iall[3,3] - Iall[3,1:2] %*% solve(Iall[1:2,1:2]) %*% Iall[1:2,3])

#+END_SRC

#+RESULTS:
:              [,1]
: [1,] 5.740945e-05
:          [,1]
: [1,] 4.928297

\clearpage

* Single breakpoint

** Theory

Consider a response variable \(Y\) and an explanatory variable \(X\)
related by:
#+BEGIN_EXPORT latex
\begin{align*}
Y = \beta X + \gamma (X - \psi)_+ + \varepsilon
\end{align*}
#+END_EXPORT

\noindent where \((\beta,\gamma,\psi) \in \Real^3\), \(\varepsilon
\sim \Gaus[0,\sigma^2]\), and \((x)_+=x\) if \(x>0\) and 0
otherwise. Introduce \(\Theta = (\beta,\gamma,\psi,\sigma^2)\), we can
express the likelihood relative to \(n\) iid observations as:
#+BEGIN_EXPORT latex
\begin{align*}
\Likelihood(\Theta) = \prod_{i=1}^n \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{(Y_i - \beta X_i - \gamma (X_i - \psi)_+)^2}{2\sigma^2}\right)
\end{align*}
#+END_EXPORT
and the log-likelihood as:
#+BEGIN_EXPORT latex
\begin{align*}
\likelihood(\Theta) = - \frac{n}{2} \log(2\pi) - \frac{n}{2} \log(\sigma^2) - \sum_{i=1}^n \frac{\left(Y_i - \beta X_i - \gamma (X_i - \psi)_+\right)^2}{2\sigma^2}
\end{align*}
#+END_EXPORT

\noindent Maximizing the likelihood with respect to \(\Theta_\mu =
(\beta,\gamma,\psi)\) is equivalent to minimizing the mean squared
error:
#+BEGIN_EXPORT latex
\begin{align*}
\likelihood(\Theta_\mu) = \sum_{i=1}^n (Y_i - \beta X_i - \gamma (X_i - \psi)_+)^2
\end{align*}
#+END_EXPORT

\noindent which is equivalent to first minimizing
w.r.t. \((\beta,\gamma)\), i.e. plug-in the OLS estimator:
#+BEGIN_EXPORT latex
\begin{align*}
(\widehat{\beta},\widehat{\gamma}) = \left(\begin{bmatrix} X \\ (X - \psi)_+ \end{bmatrix} \begin{bmatrix} X & (X - \psi)_+ \end{bmatrix} \right)^{-1} \begin{bmatrix} X \\ (X - \psi)_+ \end{bmatrix} Y \\
= \begin{bmatrix} \trans{X}X & \trans{X}(X - \psi)_+ \\  \trans{X}(X - \psi)_+ & \trans{(X - \psi)_+} (X - \psi)_+ \end{bmatrix}^{-1} \begin{bmatrix} \trans{X} Y \\ \trans{(X - \psi)_+} Y \end{bmatrix}  \\
= \frac{\begin{bmatrix} \trans{(X - \psi)_+} (X - \psi)_+ & -\trans{X}(X - \psi)_+ \\  -\trans{X}(X - \psi)_+ & \trans{X}X \end{bmatrix} \begin{bmatrix} \trans{X} Y \\ \trans{(X - \psi)_+} Y \end{bmatrix} }{\trans{X}X\trans{(X - \psi)_+} (X - \psi)_+ -\trans{X}(X - \psi)_+\trans{X}(X - \psi)_+} 
\end{align*}
#+END_EXPORT

where \(Y = (Y_1,\ldots,Y_n)\) and \(X=(X_1,\ldots,X_n)\). We therefore obtain:
#+BEGIN_EXPORT latex
\begin{align*}
\tilde{\beta}(\psi) &= \frac{ \trans{(X - \psi)_+} (X - \psi)_+ \trans{X} Y -\trans{X}(X - \psi)_+ \trans{(X - \psi)_+} Y }{\trans{X}X\trans{(X - \psi)_+} (X - \psi)_+ -\trans{X}(X - \psi)_+ \trans{X}(X - \psi)_+}  \\
\tilde{\gamma}(\psi) &= \frac{ \trans{X} X \trans{(X - \psi)_+} Y -\trans{X}(X - \psi)_+ \trans{X} Y }{\trans{X}X\trans{(X - \psi)_+} (X - \psi)_+ -\trans{X}(X - \psi)_+ \trans{X}(X - \psi)_+}  
\end{align*}
#+END_EXPORT

and then minimize w.r.t. \(\psi\):
#+BEGIN_EXPORT latex
\begin{align*}
\likelihood(\psi) &= \sum_{i=1}^n (Y_i - \tilde{\beta}(\psi) X_i - \tilde{\gamma}(\psi) (X_i - \psi)_+)^2
\end{align*}
#+END_EXPORT

Its first derivative is:
#+BEGIN_EXPORT latex
\begin{align*}
0 &= -2 \sum_{i=1}^n \left[
  \frac{\partial \tilde{\beta}(\psi)}{\partial \psi} X_i
+ \frac{\partial \tilde{\gamma}(\psi)}{\partial \psi}(X_i - \psi)_+
+ \tilde{\gamma}(\psi)\frac{\partial (X_i - \psi)_+}{\partial \psi}\right]
(Y_i - \tilde{\beta}(\psi) X_i - \tilde{\gamma}(\psi) (X_i - \psi)_+)
\end{align*}
#+END_EXPORT

\clearpage

** Example

#+BEGIN_SRC R :exports both :results output :session *R* :cache no
library(lmbreak)

set.seed(10)
df11 <- simBreak(c(1, 100), breakpoint = c(0,2,4),
                 slope = c(1,0), sigma = 0.05)
e.lmbreak11 <- lmbreak(Y ~ 0 + bp(X, pattern = "11", start = c(2)),
                       data = df11)
model.tables(e.lmbreak11)
#+END_SRC

#+RESULTS:
:            X duration intercept      slope
: 1 0.05773562 1.926807  0.000000 1.00316914
: 2 1.98454227 1.860667  1.932913 0.01677379
: 3 3.84520966       NA  1.964123         NA

OLS:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
XX <- cbind(df11$X, pmax(df11$X-coef(e.lmbreak11),0))
solve(t(XX) %*% XX) %*% t(XX) %*% df11$Y
#+END_SRC

#+RESULTS:
:            [,1]
: [1,]  1.0031692
: [2,] -0.9863952

Explicit OLS:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
(crossprod(XX[,2]) * crossprod(XX[,1],df11$Y) - crossprod(XX[,1],XX[,2]) * crossprod(XX[,2],df11$Y)) / (crossprod(XX[,1]) * crossprod(XX[,2]) - crossprod(XX[,1],XX[,2])^2)
(crossprod(XX[,1]) * crossprod(XX[,2],df11$Y) - crossprod(XX[,1],XX[,2]) * crossprod(XX[,1],df11$Y)) / (crossprod(XX[,1]) * crossprod(XX[,2]) - crossprod(XX[,1],XX[,2])^2)
#+END_SRC

#+RESULTS:
:          [,1]
: [1,] 1.003169
:            [,1]
: [1,] -0.9863952

Full likelihood:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
calcLogLik <- function(theta){
  beta <- theta["beta"]
  gamma <- theta["gamma"]
  psi <- theta["psi"]
  sigma <- theta["sigma"]
  as.double(-NROW(df11)/2 * log(2*pi) - NROW(df11)/2 * log(sigma) - sum((df11$Y - beta * df11$X - gamma * pmax(df11$X - psi,0))^2)/(2*sigma))
}
theta <- c(beta = unname(coef(e.lmbreak11$model)["Us0"]),
           gamma = unname(coef(e.lmbreak11$model)["Us1"]),
           psi = 1.98454227,
           sigma = sigma(e.lmbreak11$model)^2)
calcLogLik(theta = theta)
logLik(e.lmbreak11$model)
#+END_SRC

#+RESULTS:
: [1] 162.2538
: 'log Lik.' 162.2768 (df=4)

Profile likelihood:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
calcProfLik <- function(psi){ ## psi <- 1
  XX <- cbind(df11$X, pmax(df11$X-psi,0))
  OLS <- as.double(solve(t(XX) %*% XX) %*% t(XX) %*% df11$Y)
  sigma <- sum((df11$Y - XX %*% OLS)^2)/(NROW(df11)-3)
   - NROW(df11)/2 * log(2*pi) - NROW(df11)/2 * log(sigma) - (NROW(df11)-3)/2
}
calcProfLik(theta["psi"])

df.gridPsi <- data.frame(psi = seq(0.5,3.5,length.out=1000))
df.gridPsi$logLik <- sapply(df.gridPsi$psi,calcProfLik)
ggplot(df.gridPsi, aes(x=psi,y=logLik)) + geom_line()
#+END_SRC

#+RESULTS:
: [1] 162.2538


Score:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
library(numDeriv)
jacobian(calcLogLik, theta)
jacobian(calcProfLik, theta["psi"])
#+END_SRC
#+RESULTS:
:            [,1]        [,2]        [,3]      [,4]
: [1,] 0.02242403 0.006498193 0.007915766 -638.0514
:             [,1]
: [1,] 0.001578588

Hessian:
#+BEGIN_SRC R :exports both :results output :session *R* :cache no
Hall <- hessian(calcLogLik, theta)
Iall <- solve(-Hall)

Iall[3,3] - Iall[3,1:2] %*% solve(Iall[1:2,1:2]) %*% Iall[1:2,3]

Hpsi <- hessian(calcProfLik, theta["psi"])
Ipsi <- solve(-Hpsi)

Ipsi/(Iall[3,3] - Iall[3,1:2] %*% solve(Iall[1:2,1:2]) %*% Iall[1:2,3])

#+END_SRC

#+RESULTS:
:              [,1]
: [1,] 5.740945e-05
:          [,1]
: [1,] 4.928297

\clearpage

* Multiple breakpoints

We now consider the more general case where:
#+BEGIN_EXPORT latex
\begin{align*}
Y = \beta X(\psi) + \varepsilon
\end{align*}
#+END_EXPORT
where \(\beta\) is a vector of coefficients and \(X(\psi)\) the design
matrix depending on a vector of breakpoint \(\psi\). Similarly to the
previous derivations we need to minimize the mean square loss:
#+BEGIN_EXPORT latex
\begin{align*}
\sum_{i=1}^n \left(Y_i - \beta X_i(\psi)\right)^2
\end{align*}
#+END_EXPORT

with respect to \(\beta\) and \(\psi\). For given \(\psi\) the
coefficient \(\beta\) minimizing this loss are given by the OLS
estimator:
#+BEGIN_EXPORT latex
\begin{align*}
\widehat{\beta} = (\trans{X}(\psi)X(\psi))^{-1}\trans{X}(\psi) Y
\end{align*}
#+END_EXPORT

\clearpage

* Proximal gradient method

One difficulty is that this objective function is not differientiable
in \(\psi\) at \(\left(X_i\right)_{i=1}^n\). 

\bigskip

\(\likelihood(\Theta_\mu)\) might not be strictly convex but it is
convex. So we can try applying a proximal gradient algorithm. This
means updating the estimate by:
#+BEGIN_EXPORT latex
\begin{align*}
\Theta_{\mu,k+1} &= \text{prox}_{\alpha_k \likelihood}(\Theta_{\mu,k}) = \argmin_{\Theta_\mu \in \Real^2} \left( \likelihood(\Theta_\mu) + \frac{1}{2\alpha_k}||\Theta_\mu-\Theta_{\mu,k}||^2 \right) \\
&= \argmin_{\Theta_\mu \in \Real^3} \left( \sum_{i=1} (Y_i - \beta X_i - \gamma (X_i - \psi)_+)^2 + \frac{(\beta - \beta_k)^2+(\gamma - \gamma_k)^2+(\psi - \psi_k)^2}{2\alpha_k} \right) 
&= \argmin_{\psi \in \Real} \left((I - Z)(\trans{Z}Z)^{-1}ZY + \frac{(\beta - \beta_k)^2+(\gamma - \gamma_k)^2+(\psi - \psi_k)^2}{2\alpha_k}  \right)
\end{align*}
#+END_EXPORT
where \(\alpha_k\) is a pre-defined stricly positive real value.


# However we can re-write
# the objective function as:
# #+BEGIN_EXPORT latex
# \begin{align*}
# \likelihood(\Theta_\mu) &= \textcolor{\darkblue}{\sum_{i=1} (Y_i - \alpha - \beta X_i)^2} + \textcolor{\darkred}{\gamma^2 \sum_{i=1} (X_i - \psi)_+^2 - 2 \gamma (Y_i - \alpha - \beta X_i)(X_i - \psi)_+} \\
# &= \textcolor{\darkblue}{f(\alpha,\beta)} + \textcolor{\darkred}{g(\alpha,\beta,\psi)}
# \end{align*}
# #+END_EXPORT
# where \(f\) is differientable and \(g\) is not differentiable.

# @@latex:any arbitrary LaTeX code@@

* CONFIG :noexport:
# #+LaTeX_HEADER:\affil{Department of Biostatistics, University of Copenhagen, Copenhagen, Denmark}
#+LANGUAGE:  en
#+LaTeX_CLASS: org-article
#+LaTeX_CLASS_OPTIONS: [12pt]
#+OPTIONS:   title:t author:t toc:nil todo:nil date:nil
#+OPTIONS:   H:3 num:t 
#+OPTIONS:   TeX:t LaTeX:t
#+LATEX_HEADER: %
#+LATEX_HEADER: %%%% specifications %%%%
#+LATEX_HEADER: %
** Latex command
#+LATEX_HEADER: \usepackage{ifthen}
#+LATEX_HEADER: \usepackage{xifthen}
#+LATEX_HEADER: \usepackage{xargs}
#+LATEX_HEADER: \usepackage{xspace}
** Notations
** Code
# Documentation at https://org-babel.readthedocs.io/en/latest/header-args/#results
# :tangle (yes/no/filename) extract source code with org-babel-tangle-file, see http://orgmode.org/manual/Extracting-source-code.html 
# :cache (yes/no)
# :eval (yes/no/never)
# :results (value/output/silent/graphics/raw/latex)
# :export (code/results/none/both)
#+PROPERTY: header-args :session *R* :tangle yes :cache no ## extra argument need to be on the same line as :session *R*
# Code display:
#+LATEX_HEADER: \RequirePackage{fancyvrb}
#+LATEX_HEADER: \DefineVerbatimEnvironment{verbatim}{Verbatim}{fontsize=\small,formatcom = {\color[rgb]{0.5,0,0}}}
# ## change font size input
# ## #+ATTR_LATEX: :options basicstyle=\ttfamily\scriptsize
# ## change font size output
# ## \RecustomVerbatimEnvironment{verbatim}{Verbatim}{fontsize=\tiny,formatcom = {\color[rgb]{0.5,0,0}}}
** Display 
#+LATEX_HEADER: \RequirePackage{colortbl} % arrayrulecolor to mix colors
#+LATEX_HEADER: \RequirePackage{setspace} % to modify the space between lines - incompatible with footnote in beamer
#+LaTeX_HEADER:\renewcommand{\baselinestretch}{1.1}
#+LATEX_HEADER:\geometry{top=1cm}
#+LATEX_HEADER: \RequirePackage{colortbl} % arrayrulecolor to mix colors
# ## valid and cross symbols
#+LaTeX_HEADER: \RequirePackage{pifont}
#+LaTeX_HEADER: \RequirePackage{relsize}
#+LaTeX_HEADER: \newcommand{\Cross}{{\raisebox{-0.5ex}%
#+LaTeX_HEADER:		{\relsize{1.5}\ding{56}}}\hspace{1pt} }
#+LaTeX_HEADER: \newcommand{\Valid}{{\raisebox{-0.5ex}%
#+LaTeX_HEADER:		{\relsize{1.5}\ding{52}}}\hspace{1pt} }
#+LaTeX_HEADER: \newcommand{\CrossR}{ \textcolor{red}{\Cross} }
#+LaTeX_HEADER: \newcommand{\ValidV}{ \textcolor{green}{\Valid} }
# ## warning symbol
#+LaTeX_HEADER: \usepackage{stackengine}
#+LaTeX_HEADER: \usepackage{scalerel}
#+LaTeX_HEADER: \newcommand\Warning[1][3ex]{%
#+LaTeX_HEADER:   \renewcommand\stacktype{L}%
#+LaTeX_HEADER:   \scaleto{\stackon[1.3pt]{\color{red}$\triangle$}{\tiny\bfseries !}}{#1}%
#+LaTeX_HEADER:   \xspace
#+LaTeX_HEADER: }
# # change the color of the links
#+LaTeX_HEADER: \hypersetup{
#+LaTeX_HEADER:  citecolor=[rgb]{0,0.5,0},
#+LaTeX_HEADER:  urlcolor=[rgb]{0,0,0.5},
#+LaTeX_HEADER:  linkcolor=[rgb]{0,0,0.5},
#+LaTeX_HEADER: }
** Image
#+LATEX_HEADER: \RequirePackage{epstopdf} % to be able to convert .eps to .pdf image files
#+LATEX_HEADER: \RequirePackage{capt-of} % 
#+LATEX_HEADER: \RequirePackage{caption} % newlines in graphics
#+LATEX_HEADER: \RequirePackage{tikz}
# ## R logo
#+LATEX_HEADER:\definecolor{grayR}{HTML}{8A8990}
#+LATEX_HEADER:\definecolor{grayL}{HTML}{C4C7C9}
#+LATEX_HEADER:\definecolor{blueM}{HTML}{1F63B5}
#+LATEX_HEADER: \newcommand{\Rlogo}[1][0.07]{
#+LATEX_HEADER: \begin{tikzpicture}[scale=#1]
#+LATEX_HEADER: \shade [right color=grayR,left color=grayL,shading angle=60] 
#+LATEX_HEADER: (-3.55,0.3) .. controls (-3.55,1.75) 
#+LATEX_HEADER: and (-1.9,2.7) .. (0,2.7) .. controls (2.05,2.7)  
#+LATEX_HEADER: and (3.5,1.6) .. (3.5,0.3) .. controls (3.5,-1.2) 
#+LATEX_HEADER: and (1.55,-2) .. (0,-2) .. controls (-2.3,-2) 
#+LATEX_HEADER: and (-3.55,-0.75) .. cycle;
#+LATEX_HEADER: 
#+LATEX_HEADER: \fill[white] 
#+LATEX_HEADER: (-2.15,0.2) .. controls (-2.15,1.2) 
#+LATEX_HEADER: and (-0.7,1.8) .. (0.5,1.8) .. controls (2.2,1.8) 
#+LATEX_HEADER: and (3.1,1.2) .. (3.1,0.2) .. controls (3.1,-0.75) 
#+LATEX_HEADER: and (2.4,-1.45) .. (0.5,-1.45) .. controls (-1.1,-1.45) 
#+LATEX_HEADER: and (-2.15,-0.7) .. cycle;
#+LATEX_HEADER: 
#+LATEX_HEADER: \fill[blueM] 
#+LATEX_HEADER: (1.75,1.25) -- (-0.65,1.25) -- (-0.65,-2.75) -- (0.55,-2.75) -- (0.55,-1.15) -- 
#+LATEX_HEADER: (0.95,-1.15)  .. controls (1.15,-1.15) 
#+LATEX_HEADER: and (1.5,-1.9) .. (1.9,-2.75) -- (3.25,-2.75)  .. controls (2.2,-1) 
#+LATEX_HEADER: and (2.5,-1.2) .. (1.8,-0.95) .. controls (2.6,-0.9) 
#+LATEX_HEADER: and (2.85,-0.35) .. (2.85,0.2) .. controls (2.85,0.7) 
#+LATEX_HEADER: and (2.5,1.2) .. cycle;
#+LATEX_HEADER: 
#+LATEX_HEADER: \fill[white]  (1.4,0.4) -- (0.55,0.4) -- (0.55,-0.3) -- (1.4,-0.3).. controls (1.75,-0.3) 
#+LATEX_HEADER: and (1.75,0.4) .. cycle;
#+LATEX_HEADER: 
#+LATEX_HEADER: \end{tikzpicture}
#+LATEX_HEADER: }
** List
#+LATEX_HEADER: \RequirePackage{enumitem} % to be able to convert .eps to .pdf image files
** Color
#+LaTeX_HEADER: \definecolor{light}{rgb}{1, 1, 0.9}
#+LaTeX_HEADER: \definecolor{lightred}{rgb}{1.0, 0.7, 0.7}
#+LaTeX_HEADER: \definecolor{lightblue}{rgb}{0.0, 0.8, 0.8}
#+LaTeX_HEADER: \newcommand{\darkblue}{blue!80!black}
#+LaTeX_HEADER: \newcommand{\darkgreen}{green!50!black}
#+LaTeX_HEADER: \newcommand{\darkred}{red!50!black}
** Box
#+LATEX_HEADER: \usepackage{mdframed}
** Shortcut
#+LATEX_HEADER: \newcommand{\first}{1\textsuperscript{st} }
#+LATEX_HEADER: \newcommand{\second}{2\textsuperscript{nd} }
#+LATEX_HEADER: \newcommand{\third}{3\textsuperscript{rd} }
** Algorithm
#+LATEX_HEADER: \RequirePackage{amsmath}
#+LATEX_HEADER: \RequirePackage{algorithm}
#+LATEX_HEADER: \RequirePackage[noend]{algpseudocode}
** Math
#+LATEX_HEADER: \RequirePackage{dsfont}
#+LATEX_HEADER: \RequirePackage{amsmath,stmaryrd,graphicx}
#+LATEX_HEADER: \RequirePackage{prodint} % product integral symbol (\PRODI)
# ## lemma
# #+LaTeX_HEADER: \RequirePackage{amsthm}
# #+LaTeX_HEADER: \newtheorem{theorem}{Theorem}
# #+LaTeX_HEADER: \newtheorem{lemma}[theorem]{Lemma}
*** Template for shortcut
#+LATEX_HEADER: \newcommand\defOperator[7]{%
#+LATEX_HEADER:	\ifthenelse{\isempty{#2}}{
#+LATEX_HEADER:		\ifthenelse{\isempty{#1}}{#7{#3}#4}{#7{#3}#4 \left#5 #1 \right#6}
#+LATEX_HEADER:	}{
#+LATEX_HEADER:	\ifthenelse{\isempty{#1}}{#7{#3}#4_{#2}}{#7{#3}#4_{#1}\left#5 #2 \right#6}
#+LATEX_HEADER: }
#+LATEX_HEADER: }
#+LATEX_HEADER: \newcommand\defUOperator[5]{%
#+LATEX_HEADER: \ifthenelse{\isempty{#1}}{
#+LATEX_HEADER:		#5\left#3 #2 \right#4
#+LATEX_HEADER: }{
#+LATEX_HEADER:	\ifthenelse{\isempty{#2}}{\underset{#1}{\operatornamewithlimits{#5}}}{
#+LATEX_HEADER:		\underset{#1}{\operatornamewithlimits{#5}}\left#3 #2 \right#4}
#+LATEX_HEADER: }
#+LATEX_HEADER: }
#+LATEX_HEADER: \newcommand{\defBoldVar}[2]{	
#+LATEX_HEADER:	\ifthenelse{\equal{#2}{T}}{\boldsymbol{#1}}{\mathbf{#1}}
#+LATEX_HEADER: }
*** Shortcuts
**** Probability
#+LATEX_HEADER: \newcommandx\Cov[2][1=,2=]{\defOperator{#1}{#2}{C}{ov}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Esp[2][1=,2=]{\defOperator{#1}{#2}{E}{}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Prob[2][1=,2=]{\defOperator{#1}{#2}{P}{}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Qrob[2][1=,2=]{\defOperator{#1}{#2}{Q}{}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Var[2][1=,2=]{\defOperator{#1}{#2}{V}{ar}{\lbrack}{\rbrack}{\mathbb}}
#+LATEX_HEADER: \newcommandx\Binom[2][1=,2=]{\defOperator{#1}{#2}{B}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Gaus[2][1=,2=]{\defOperator{#1}{#2}{N}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Wishart[2][1=,2=]{\defOperator{#1}{#2}{W}{ishart}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Likelihood[2][1=,2=]{\defOperator{#1}{#2}{L}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\likelihood[2][1=,2=]{\defOperator{#1}{#2}{\ell}{}{(}{)}{}}
#+LATEX_HEADER: \newcommandx\Information[2][1=,2=]{\defOperator{#1}{#2}{I}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Score[2][1=,2=]{\defOperator{#1}{#2}{S}{}{(}{)}{\mathcal}}
**** Operators
#+LATEX_HEADER: \newcommandx\Vois[2][1=,2=]{\defOperator{#1}{#2}{V}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\IF[2][1=,2=]{\defOperator{#1}{#2}{IF}{}{(}{)}{\mathcal}}
#+LATEX_HEADER: \newcommandx\Ind[1][1=]{\defOperator{}{#1}{1}{}{(}{)}{\mathds}}
#+LATEX_HEADER: \newcommandx\Max[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{min}}
#+LATEX_HEADER: \newcommandx\Min[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{max}}
#+LATEX_HEADER: \newcommandx\argMax[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{argmax}}
#+LATEX_HEADER: \newcommandx\argMin[2][1=,2=]{\defUOperator{#1}{#2}{(}{)}{argmin}}
#+LATEX_HEADER: \newcommandx\cvD[2][1=D,2=n \rightarrow \infty]{\xrightarrow[#2]{#1}}
#+LATEX_HEADER: \newcommandx\Hypothesis[2][1=,2=]{
#+LATEX_HEADER:         \ifthenelse{\isempty{#1}}{
#+LATEX_HEADER:         \mathcal{H}
#+LATEX_HEADER:         }{
#+LATEX_HEADER: 	\ifthenelse{\isempty{#2}}{
#+LATEX_HEADER: 		\mathcal{H}_{#1}
#+LATEX_HEADER: 	}{
#+LATEX_HEADER: 	\mathcal{H}^{(#2)}_{#1}
#+LATEX_HEADER:         }
#+LATEX_HEADER:         }
#+LATEX_HEADER: }
#+LATEX_HEADER: \newcommandx\dpartial[4][1=,2=,3=,4=\partial]{
#+LATEX_HEADER: 	\ifthenelse{\isempty{#3}}{
#+LATEX_HEADER: 		\frac{#4 #1}{#4 #2}
#+LATEX_HEADER: 	}{
#+LATEX_HEADER: 	\left.\frac{#4 #1}{#4 #2}\right\rvert_{#3}
#+LATEX_HEADER: }
#+LATEX_HEADER: }
#+LATEX_HEADER: \newcommandx\dTpartial[3][1=,2=,3=]{\dpartial[#1][#2][#3][d]}
#+LATEX_HEADER: \newcommandx\ddpartial[3][1=,2=,3=]{
#+LATEX_HEADER: 	\ifthenelse{\isempty{#3}}{
#+LATEX_HEADER: 		\frac{\partial^{2} #1}{\partial #2^2}
#+LATEX_HEADER: 	}{
#+LATEX_HEADER: 	\frac{\partial^2 #1}{\partial #2\partial #3}
#+LATEX_HEADER: }
#+LATEX_HEADER: } 
**** General math
#+LATEX_HEADER: \newcommand\Real{\mathbb{R}}
#+LATEX_HEADER: \newcommand\Rational{\mathbb{Q}}
#+LATEX_HEADER: \newcommand\Natural{\mathbb{N}}
#+LATEX_HEADER: \newcommand\trans[1]{{#1}^\intercal}%\newcommand\trans[1]{{\vphantom{#1}}^\top{#1}}
#+LATEX_HEADER: \newcommand{\independent}{\mathrel{\text{\scalebox{1.5}{$\perp\mkern-10mu\perp$}}}}
#+LaTeX_HEADER: \newcommand\half{\frac{1}{2}}
#+LaTeX_HEADER: \newcommand\normMax[1]{\left|\left|#1\right|\right|_{max}}
#+LaTeX_HEADER: \newcommand\normTwo[1]{\left|\left|#1\right|\right|_{2}}
#+LaTeX_HEADER: \DeclareMathOperator*{\argmax}{arg\,max}
#+LaTeX_HEADER: \DeclareMathOperator*{\argmin}{arg\,min}
